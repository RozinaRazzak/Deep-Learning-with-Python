{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiating the VGG16 convolutional base"
      ],
      "metadata": {
        "id": "8yDtt6BP-evM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "model = VGG16(weights = 'imagenet',\n",
        "              include_top = False)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Qq8B90mK_X6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a feature extraction model"
      ],
      "metadata": {
        "id": "9JxWI_rM_bDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "layer_name = 'block1_conv1'\n",
        "layer_output = model.get_layer(layer_name)\n",
        "feature_extractor = keras.Model(inputs = model.inputs, outputs = layer_output.output)"
      ],
      "metadata": {
        "id": "xTG8LeuHvKTd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the gradient ascent process"
      ],
      "metadata": {
        "id": "tgd-0vYbEMIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def compute_loss(input_image, filter_index):\n",
        "  activation = feature_extractor(input_image)\n",
        "  filter_activation = activation[:,2:-2, 2:2, filter_index]\n",
        "  return tf.reduce_mean(filter_activation)"
      ],
      "metadata": {
        "id": "pLvIuIQWWcc8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def gradient_ascent_step(img, filter_index, learning_rate):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(img)\n",
        "    loss = compute_loss(img, filter_index)\n",
        "\n",
        "  grads = tape.gradient(loss, img)\n",
        "  grads = tf.math.l2_normalize(grads)\n",
        "  img += learning_rate * grads\n",
        "  return loss, img"
      ],
      "metadata": {
        "id": "3m8AtboyWsXe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the end to end filter visualization loop"
      ],
      "metadata": {
        "id": "5EKUUjHEEh3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "img_width = 180\n",
        "img_height = 180\n",
        "def initialize_image():\n",
        "  img = tf.random.uniform((1, img_width, img_height,3))\n",
        "  return (img - 0.5) * 0.25\n",
        "\n",
        "def visualize_filter(filter_index):\n",
        "  iterations = 30\n",
        "  learning_rate = 0.01\n",
        "  img = initialize_image()\n",
        "  for iteration in range(iterations):\n",
        "    loss, img = gradient_ascent_step(img, filter_index, learning_rate)\n",
        "\n",
        "  img = deprocess_image(img[0].numpy())\n",
        "  return loss, img\n",
        "\n",
        "def deprocess_image(img):\n",
        "  img -= img.mean()\n",
        "  img /= img.std() + 1e-5\n",
        "  img *= 0.15\n",
        "\n",
        "  img = img[25:-25, 25:-25,:]\n",
        "\n",
        "  img += 0.5\n",
        "  img = np.clip(img, 0,1)\n",
        "\n",
        "  img *= 255\n",
        "  img = np.clip(img, 0, 255).astype('uint8')\n",
        "  return img"
      ],
      "metadata": {
        "id": "kF6DflrEecFP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "loss, img = visualize_filter(0)\n",
        "keras.utils.save_img('0.png', img)\n",
        "display(Image('0.png'))"
      ],
      "metadata": {
        "id": "4ih0P1csoCGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the first 64 filters in the target layer"
      ],
      "metadata": {
        "id": "IY2NURlDFdNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_imgs = []\n",
        "for filter_index in range(64):\n",
        "  print('Processing filter %d' %(filter_index))\n",
        "  loss, img =visualize_filter(filter_index)\n",
        "  all_imgs.append(img)\n",
        "\n",
        "margin = 5\n",
        "n = 8\n",
        "cropped_width = img_width - 25 * 2\n",
        "cropped_height = img_height - 25 * 2\n",
        "width = n * cropped_width + (n - 1) * margin\n",
        "height = n * cropped_height + (n - 1) * margin\n",
        "stitched_filters = np.zeros((width, height, 3))\n",
        "\n",
        "for i in range(n):\n",
        "  for j in range(n):\n",
        "    img = all_imgs[i * n + j]\n",
        "    stitched_filters[\n",
        "        (cropped_width + margin) * i : (cropped_width + margin) * i + cropped_width,\n",
        "        (cropped_height + margin) * j : (cropped_height + margin) * j + cropped_height,:] = img\n",
        "\n",
        "keras.utils.save_img('stitched_filters.png', stitched_filters)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image('stitched_filters.png'))"
      ],
      "metadata": {
        "id": "CFuw4Ix7op1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n24IkCKsGMDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}