{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the VGG16 network with pretained weights"
      ],
      "metadata": {
        "id": "Ia54R5VUq--j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pg1wBcD8rnXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.applications.vgg16.VGG16(weights = 'imagenet')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "g7_DsEVJ5Wsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing an input image for VGG16"
      ],
      "metadata": {
        "id": "iIVlnKHItPPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = keras.utils.get_file(\n",
        "    fname = 'elephant.jpg',\n",
        "    origin = 'https://img-datasets.s3.amazonaws.com/elephant.jpg')"
      ],
      "metadata": {
        "id": "W1eBJ2xVtXXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_array(img_path, target_size):\n",
        "  img = keras.utils.load_img(img_path, target_size = target_size)\n",
        "  array = keras.utils.img_to_array(img)\n",
        "  array = np.expand_dims(array,axis = 0)\n",
        "  array = keras.applications.vgg16.preprocess_input(array)\n",
        "  return array"
      ],
      "metadata": {
        "id": "fMAq0Y6U52wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = get_img_array(img_path,target_size = ((224,224)))"
      ],
      "metadata": {
        "id": "T_mJueSU6sqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(img_array)\n",
        "print(keras.applications.vgg16.decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "id": "pEBh_wAW7hTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(preds[0])"
      ],
      "metadata": {
        "id": "69lxxByLJaay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up a model that returns the last convolutional output"
      ],
      "metadata": {
        "id": "s7Ykmxg_Jd0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_conv_layer_name = 'block5_conv3'\n",
        "classifier_layer_name = ['block5_pool','flatten', 'fc1','fc2','predictions']\n",
        "last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)"
      ],
      "metadata": {
        "id": "Al1z1OOdJkLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reapplying the classifier on top of the last convolutional output"
      ],
      "metadata": {
        "id": "PP0E0jYJJ_yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_input = keras.Input(shape = last_conv_layer.output.shape[1:])\n",
        "x = classifier_input\n",
        "for layer_name in classifier_layer_name:\n",
        "  x = model.get_layer(layer_name)(x)\n",
        "classifier_model = keras.Model(classifier_input, x)"
      ],
      "metadata": {
        "id": "fMf3qC7fnmao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieving the gradients of the top predicted class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3xzzJxYRL6BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "  tape.watch(last_conv_layer_output)\n",
        "  preds = classifier_model(last_conv_layer_output)\n",
        "  top_pred_index = tf.argmax(preds[0])\n",
        "  top_class_channel = preds[:,top_pred_index]\n",
        "\n",
        "grads = tape.gradient(top_class_channel, last_conv_layer_output)"
      ],
      "metadata": {
        "id": "Pf2yxWKWMBIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient pooling and channel importance weighting"
      ],
      "metadata": {
        "id": "QgP4GwxHM2wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_grads = tf.reduce_mean(grads, axis = (0,1,2)).numpy()\n",
        "last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "for i in range(pooled_grads.shape[-1]):\n",
        "  last_conv_layer_output[:,:,i] *= pooled_grads[i]\n",
        "\n",
        "heatmap = np.mean(last_conv_layer_output, axis = -1)"
      ],
      "metadata": {
        "id": "wSrA26EXM8yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heatmap post-processing"
      ],
      "metadata": {
        "id": "Ezh3sT5VNlJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = np.maximum(heatmap,0)\n",
        "heatmap /= np.max(heatmap)\n",
        "plt.matshow(heatmap)"
      ],
      "metadata": {
        "id": "AJSfAkSaNpWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Superimposing the heatmap on teh original picture"
      ],
      "metadata": {
        "id": "O-v_qoTjN2H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "img = keras.utils.load_img(img_path)\n",
        "img = keras.utils.img_to_array(img)\n",
        "\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "jet = cm.get_cmap('jet')\n",
        "jet_colors = jet(np.arange(256))[:,:3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "superimposed_img = jet_heatmap * 0.4 + img\n",
        "superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "save_path = 'elephant_cam_vgg16.jpg'\n",
        "superimposed_img.save(save_path)\n",
        "plt.imshow(superimposed_img)"
      ],
      "metadata": {
        "id": "nZoXK7ipN8AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rfGF7Hetrxbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}